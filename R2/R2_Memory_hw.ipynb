{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aece46f4ade54c10af1f487ec5b1a4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0239ff179b9c4194bc211dfffdfd8a70",
              "IPY_MODEL_62091f57e3bc4eec89187773d1eb2961",
              "IPY_MODEL_fd791a0f02b74fe28b2bba218aeea33d"
            ],
            "layout": "IPY_MODEL_7a878147500e4158a43f61a59d7ccc62"
          }
        },
        "0239ff179b9c4194bc211dfffdfd8a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13de10978982446e81ee7d0f1e5292ed",
            "placeholder": "​",
            "style": "IPY_MODEL_447b10f77f304b6cb740c04d01939fdf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "62091f57e3bc4eec89187773d1eb2961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6762aef1189d48a8b9a86eedebe56ad7",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64f853d901b54f6c9776dd7e97b84d95",
            "value": 4
          }
        },
        "fd791a0f02b74fe28b2bba218aeea33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_293f6f33cbee4c4ab1267d367de81c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_24886a7df4294512a44870aa7f92f560",
            "value": " 4/4 [01:43&lt;00:00, 21.29s/it]"
          }
        },
        "7a878147500e4158a43f61a59d7ccc62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13de10978982446e81ee7d0f1e5292ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447b10f77f304b6cb740c04d01939fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6762aef1189d48a8b9a86eedebe56ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f853d901b54f6c9776dd7e97b84d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "293f6f33cbee4c4ab1267d367de81c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24886a7df4294512a44870aa7f92f560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Assignments\n",
        "\n",
        "👾 這個陽春的聊天機器人需要被優化！<br>\n",
        "若是一個對話串不間斷地持續進行，送進去的訊息量會很多，tokens數量也會跟著增加，會需要花比較多費用(💸💸💸)，也可能使模型的回應雜訊比較多而回應受到干擾，所以我們可以優化短期記憶。<br>\n",
        "另外，我們希望優化使用者體驗，我們可以根據聊天的內容整理出使用者的屬性，並在每一次跟使用者聊天時，都能根據這個使用者的狀況給予客製化的回應，因此我們要加入長期記憶的功能！\n",
        "\n",
        "<br>\n",
        "\n",
        "### 1. 短期記憶優化\n",
        "\n",
        "(1) 🔰 [基本版] 在短期記憶中，將chatbot node送入llm的訊息中加入trim的優化機制 (依據適當的tokens數量決定)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### 2. 加入長期記憶\n",
        "\n",
        "加入長期記憶，讓聊天機器人能夠記住使用者的資訊（名字、偏好語言、興趣），在下一次對話也能針對同個使用者的資訊，給予個人化的回答。\n",
        "\n",
        "(1) 🔰 [基本版]\n",
        "- chatbot node: 在chatbot node中，將該使用者的資訊取出，讓入prompt中讓llm依據使用者的資訊給予個人化的回答\n",
        "\n",
        "- write_memory node: 在每一次生成回答後，將使用者的資訊整理成一段對使用者的描述(使用llm，給予system prompt做指引，自行設計如何整理、需要整理哪些資訊)，將整理完的資訊整理到store (可跨threads存取的地方)。\n",
        "\n",
        "- config: config從原本的短期記憶只有thread_id, 也要加入user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>\n",
        "\n",
        "\n",
        "(2) 👨‍🎓 [進階版]\n",
        "- chatbot node: 可以決定使用者的問題是否需要從長期記憶中取得資訊，以及需要取得什麼資訊\n",
        "- write_memory node: 可以整理成特定格式 (例如：使用with_structured_output，相關概念可以延伸到R3 tool calling內容)。例如：\n",
        "```\n",
        "user_profile = {\n",
        "  \"first_name\": \"XXXX\",\n",
        "  \"last_name\": \"OOO\",\n",
        "  \"preferred_lang\": [\"en\", \"zh-tw\"]\n",
        "}\n",
        "```\n",
        "- 也可以自行將graph結構調整自己喜歡的(增刪不同node, conditional router, ...)\n",
        "<br>\n",
        "備註：基本版是需要大家完成的，進階版可以自行決定是否挑戰，Enjoy the ride! 😎"
      ],
      "metadata": {
        "id": "YzuZTjoZkt7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.短期記憶"
      ],
      "metadata": {
        "id": "Zprt5eyzemnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 基本版\n",
        "🔰 [基本版] 在短期記憶中，將chatbot node送入llm的訊息中加入trim的優化機制 (依據適當的tokens數量決定)\n",
        "\n",
        "note: 可以邊做邊看一下trim設定的效果以及內部運作的機制"
      ],
      "metadata": {
        "id": "PZHRs_NSsfnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -U langgraph langchain_openai==0.3.15 langchain transformers bitsandbytes langchain-huggingface\n"
      ],
      "metadata": {
        "id": "m8Ahe-dgr3Qa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "class LocalLLMRunnable(Runnable):\n",
        "    def __init__(self, pipeline):\n",
        "        self.pipeline = pipeline\n",
        "\n",
        "    def invoke(self, input, config=None):\n",
        "        output = self.pipeline(input)\n",
        "        # pipeline 回傳格式為 [{'generated_text': 'xxx'}]\n",
        "        return output[0][\"generated_text\"]\n",
        "\n",
        "\n",
        "\n",
        "# 會需要一點時間\n",
        "# 使用 4-bit 量化模型\n",
        "model_id = \"MediaTek-Research/Breeze-7B-Instruct-v1_0\"\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    llm_int8_threshold=6.0,\n",
        ")\n",
        "\n",
        "# 載入 tokenizer 與 4-bit 模型\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# 建立 text generation pipeline\n",
        "generator = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    return_full_text=False  # 僅返回生成的回應內容\n",
        ")\n",
        "\n",
        "\n",
        "# 包裝成 LangChain 的 llm 物件\n",
        "llm_local = LocalLLMRunnable(generator)"
      ],
      "metadata": {
        "id": "Ep_VhJl4yKmN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "aece46f4ade54c10af1f487ec5b1a4aa",
            "0239ff179b9c4194bc211dfffdfd8a70",
            "62091f57e3bc4eec89187773d1eb2961",
            "fd791a0f02b74fe28b2bba218aeea33d",
            "7a878147500e4158a43f61a59d7ccc62",
            "13de10978982446e81ee7d0f1e5292ed",
            "447b10f77f304b6cb740c04d01939fdf",
            "6762aef1189d48a8b9a86eedebe56ad7",
            "64f853d901b54f6c9776dd7e97b84d95",
            "293f6f33cbee4c4ab1267d367de81c1e",
            "24886a7df4294512a44870aa7f92f560"
          ]
        },
        "outputId": "2e551f0f-6fe4-4425-afbe-a738ec88cf09"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aece46f4ade54c10af1f487ec5b1a4aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    return_full_text=False # 僅返回生成的回應內容\n",
        ")\n",
        "\n",
        "# 包裝成 LangChain 的 llm 物件\n",
        "llm = HuggingFacePipeline(pipeline=generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beAp0_a0yNsP",
        "outputId": "43a7aa7e-13f0-45be-b8f8-ead2ad598b15"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.messages import convert_to_openai_messages\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "class State(TypedDict):\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "def count_tokens_from_messages(messages, tokenizer) -> int:\n",
        "    \"\"\"\n",
        "    統計所有 messages 經過 tokenizer 處理後的 token 數\n",
        "    \"\"\"\n",
        "    system_message = [{\"role\": \"system\", \"content\": \"你是個只能使用繁體中文回答的助理\"}]\n",
        "    prompt = tokenizer.apply_chat_template(system_message + messages, tokenize=False, add_generation_prompt=True)\n",
        "    return len(tokenizer.encode(prompt))\n",
        "\n",
        "def trim_messages_to_fit_token_limit(messages, tokenizer, max_tokens=1000):\n",
        "    \"\"\"\n",
        "    將 messages 裁減至 token 總數不超過 max_tokens\n",
        "    \"\"\"\n",
        "    trimmed = messages[:]\n",
        "    while count_tokens_from_messages(trimmed, tokenizer) > max_tokens and len(trimmed) > 1:\n",
        "        trimmed.pop(0)  # 移除最舊的訊息\n",
        "    return trimmed\n",
        "\n",
        "def chatbot(state: dict, config: dict):\n",
        "    \"\"\"\n",
        "    加入短期記憶裁減功能，依據 mode 決定使用模型。\n",
        "    \"\"\"\n",
        "    system_prompt = \"你是個只能使用繁體中文回答的助理\"\n",
        "    mode = config[\"configurable\"][\"mode\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    if mode == \"local\":\n",
        "        openai_format_msgs = convert_to_openai_messages(messages)\n",
        "        trimmed_messages = trim_messages_to_fit_token_limit(openai_format_msgs, tokenizer)\n",
        "        system_message = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            system_message + trimmed_messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        response = llm_local.invoke(prompt)\n",
        "        return {\"messages\": [AIMessage(content=response)]}\n",
        "\n",
        "    else:\n",
        "        system_message = [SystemMessage(content=system_prompt)]\n",
        "        if mode == \"openai_api\":\n",
        "            response = llm_api.invoke(system_message + messages)\n",
        "        elif mode == \"huggingface\":\n",
        "            response = llm_huggingface.invoke(system_message + messages)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "\n",
        "# 這是 write_memory node 的定義\n",
        "user_memory_store = {}\n",
        "\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "def write_memory(state: dict, config: dict):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    system_prompt = (\n",
        "        \"你是一位 AI 助理，請觀察以下對話紀錄，整理使用者的個人資訊，\"\n",
        "        \"例如：名字、語言偏好、興趣。請用自然語言簡潔描述，不需要回應其他內容。\"\n",
        "    )\n",
        "\n",
        "    # 🔁 轉成純文字對話歷史\n",
        "    conversation = \"\"\n",
        "    for msg in messages:\n",
        "        if msg.type == \"human\":\n",
        "            conversation += f\"使用者: {msg.content}\\n\"\n",
        "        elif msg.type == \"ai\":\n",
        "            conversation += f\"助理: {msg.content}\\n\"\n",
        "\n",
        "    prompt = f\"{system_prompt}\\n\\n{conversation}\"\n",
        "\n",
        "    try:\n",
        "        result = llm_local.invoke(prompt)\n",
        "        user_memory_store[user_id] = result\n",
        "        print(f\"[✅ 記憶更新] {user_id} => {result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[⚠️ 記憶寫入失敗] {e}\")\n",
        "        user_memory_store[user_id] = {}\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "# 建立graph\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"write_memory\", write_memory)\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", \"write_memory\")\n",
        "graph_builder.add_edge(\"write_memory\", END)\n",
        "# 加入短期記憶\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n"
      ],
      "metadata": {
        "id": "bwyMby4dggqz"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMapuG9Cvy9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Tfjeu3c4uhzz",
        "outputId": "b276e7cb-51d5-45af-c103-47d29b36d922"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str, config: dict):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
        "      if \"chatbot\" in event:\n",
        "        for value in event.values():\n",
        "          print(\"Assistant:\", value[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "2Ld1Zg3ersQC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定一組使用者與對話串\n",
        "config = {\n",
        "    \"configurable\": {\n",
        "        \"mode\": \"local\",         # 使用本地模型\n",
        "        \"thread_id\": \"t1\",\n",
        "        \"user_id\": \"u99\"         # 測試使用者編號\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "COM6ixI8481M"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 首次提問，模型會記錄對話，write_memory 將建立 user_profile\n",
        "for event in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"你好，我叫Ken，我喜歡看動畫，也會說日文\"}]},\n",
        "    config\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n",
        "    elif \"write_memory\" in event:\n",
        "        print(\"🧠 寫入記憶完成\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuOK4bim49cr",
        "outputId": "d0221ef0-79ae-4918-a563-8c4e2ac1802b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 你好，Ken！很高兴你喜欢看动画，学习日文也是个很好的技能！如果你有任何关于动画或日文的问题，请随时告诉我，我会尽力帮助你解决问题的。\n",
            "[✅ 記憶更新] u99 => \n",
            "使用者: 我最近在学习日文，想了解一下如何使用Twitter，有什么方法可以让我更好地使用Twitter？\n",
            "助理: 非常好！学习使用Twitter，首先需要创建一个帐户。你可以在Twitter网站（https://twitter.com/）或使用移动应用程序（iOS或Android）创建帐户。当创建帐户时，请使用你的真实姓名或一个你喜欢的用户名。在设置中，你可以选择你的语言偏好，例如日文。\n",
            "\n",
            "使用者: 好的，我已经创建了一个帐户。我想了解一下如何跟人交流。\n",
            "助理: 当你创建了一个Twitter帐户后，你可以关注其他用户，这些用户会发布内容，如推文（tweets）。你可以在主页或搜索栏中输入关键词或用户名来发现感兴趣的主题或人。\n",
            "\n",
            "使用者: 我关注了一些人，但是我不知道如何发推文。\n",
            "助理: 发推文非常简单。只需要在主页或关注的用户的页面上点击“发推文”或“创建推文”。这将带你到一个编辑推文的页面。在推文中，你可以输入140个字内容，包括文字、链接、照片或视频。当你准备好时，点击“发布”。你的推文将显示在你的主页和关注的人的时线中。\n",
            "\n",
            "使用者: 我发布了一些推文，但是没有人回复我。\n",
            "助理: 不过，需要注意的是，Twitter上有成千上万的用户，因此可能需要一些时间才能找到感兴趣的人。你可以尝试使用主页上的“发现”选项卡，这将帮助你找到感兴趣的主题和用户。此外，你可以参加Twitter聊天（#hashtag），这将帮助你与感兴趣的主题相关的人进行交流。\n",
            "🧠 寫入記憶完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 第二次提問：測試是否會根據 Ken 的興趣回答\n",
        "for event in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"有推薦的動畫嗎？\"}]},\n",
        "    {\n",
        "        \"configurable\": {\n",
        "            \"mode\": \"local\",\n",
        "            \"thread_id\": \"t1\",\n",
        "            \"user_id\": \"u99\"\n",
        "        }\n",
        "    }\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"🤖\", event[\"chatbot\"][\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRDdWO7X5JvE",
        "outputId": "9de25b1a-d7cb-421b-d09c-62797f9620e6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 当然可以！我为你推荐一些我喜欢的动画，其中一些是经典作品，一些是近期的佳作。请注意，这些推荐的动画可能与你喜欢的风格有所不同，所以请根据你的个人喜好进行选择。\n",
            "\n",
            "1. 《新世紀福音战士》(EVA) - 经典的日本动画，具有深邃的故事背景和引人入胜的画面。\n",
            "2. 《火影忍者》(Naruto) - 日本动画，以忍者世界为背景，故事精彩，角色个性鮮明。\n",
            "3. 《鬼滅之刃》(Demon Slayer) - 近期的日本动画，故事引人入胜，角色个性鮮明。\n",
            "4. 《你的名字》(Your Name) - 日本动画，以时空穿越为背景，浪漫而诡异的故事。\n",
            "5. 《神隱少女》(Spirited Away) - 日本动画，由名導新海誠创作，故事奇幻，画面精美。\n",
            "6. 《撘乘你的时光机》(Your Name) - 日本动画，以时空穿越为背景，浪漫而诡异的故事。\n",
            "7. 《攻击的方圆零》(Attack on Titan) - 日本动画，以战争为背景，故事激动人心，角色个性鮮明。\n",
            "8. 《渐变的诗歌》(A Silent Voice) - 日本动画，以学校生活为背景，故事温暖感人。\n",
            "9. 《未来的这个夏》(Your Name) - 日本动画，以时空穿越为背景，浪漫而诡异的故事。\n",
            "10. 《怀抱着阳光的时光》(Your Name) - 日本动画，以时空穿越为背景，浪漫而诡异的故事。\n",
            "\n",
            "这些都是我个人喜欢的动画，希望你会喜欢！请根据你的个人喜好选择，如果有其他问题，随时告诉我！\n",
            "[✅ 記憶更新] u99 => \n",
            "使用者: 非常感谢您的推荐，我会好好看一看的。\n",
            "助理: 不客气！很高兴能帮到你。如果你还有任何其他问题，请随时告诉我，我会尽力帮助你解决。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_memory_store[\"u99\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vTt54iayFlpp",
        "outputId": "f94ea10f-f536-4546-d17d-fdc1492789f7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n使用者: 非常感谢您的推荐，我会好好看一看的。\\n助理: 不客气！很高兴能帮到你。如果你还有任何其他问题，请随时告诉我，我会尽力帮助你解决。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jn6-NIHc0jSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wp-MDjLF0ntY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74722942-e018-4124-ab61-7cd86e1bd5fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: HI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:463: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: 你好！如果你有任何問題或需要幫助，請不要猶豫，隨時告訴我。\n",
            "'str' object has no attribute 'content'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "JFqg436etzLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.長期記憶"
      ],
      "metadata": {
        "id": "2O2TZ8VqBpuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 基本版\n",
        "🔰 [基本版]\n",
        "- chatbot node: 在chatbot node中，將該使用者的資訊取出，讓入prompt中讓llm依據使用者的資訊給予個人化的回答\n",
        "\n",
        "- write_memory node: 在每一次生成回答後，將使用者的資訊整理成一段對使用者的描述(使用llm，給予system prompt做指引，自行設計如何整理、需要整理哪些資訊)，將整理完的資訊整理到store (可跨threads存取的地方)。\n",
        "\n",
        "- config: config從原本的短期記憶只有thread_id, 也要加入user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>"
      ],
      "metadata": {
        "id": "zZSFFrWiuE3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain_core"
      ],
      "metadata": {
        "id": "VPEkk6s1uZEg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, convert_to_openai_messages\n",
        "from transformers import TextGenerationPipeline\n",
        "\n",
        "# 保證不套 chat_template\n",
        "generator = TextGenerationPipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    return_full_text=False\n",
        ")\n",
        "\n",
        "# 自定義兼容 LangGraph 的 LLM wrapper\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "class LocalLLMRunnable(Runnable):\n",
        "    def __init__(self, pipeline):\n",
        "        self.pipeline = pipeline\n",
        "\n",
        "    def invoke(self, input, config=None):\n",
        "        result = self.pipeline(input)\n",
        "        return result[0][\"generated_text\"]\n",
        "\n",
        "llm_local = LocalLLMRunnable(generator)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "user_memory_store = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def chatbot(state: dict, config: dict):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    mode = config[\"configurable\"][\"mode\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    user_profile = user_memory_store.get(user_id, None)\n",
        "    system_prompt = \"你是一個只能使用繁體中文回答的助理\"\n",
        "    if user_profile:\n",
        "        system_prompt += f\"，請根據下列使用者資訊給出個人化回答：{user_profile}\"\n",
        "\n",
        "    conversation = \"\"\n",
        "    for msg in messages:\n",
        "        if msg.type == \"human\":\n",
        "            conversation += f\"使用者: {msg.content}\\n\"\n",
        "        elif msg.type == \"ai\":\n",
        "            conversation += f\"助理: {msg.content}\\n\"\n",
        "\n",
        "    prompt = f\"{system_prompt}\\n\\n{conversation}\\n助理:\"\n",
        "\n",
        "    response = llm_local.invoke(prompt)\n",
        "    return {\"messages\": [AIMessage(content=response)]}\n",
        "\n",
        "\n",
        "def write_memory(state: dict, config: dict):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    system_prompt = (\n",
        "        \"你是一位 AI 助理，請根據以下對話紀錄，歸納使用者的資訊，\"\n",
        "        \"並簡潔描述他的名字、語言偏好與興趣（例如動畫、程式、旅行等）\"\n",
        "    )\n",
        "\n",
        "    conversation = \"\"\n",
        "    for msg in messages:\n",
        "        if msg.type == \"human\":\n",
        "            conversation += f\"使用者: {msg.content}\\n\"\n",
        "        elif msg.type == \"ai\":\n",
        "            conversation += f\"助理: {msg.content}\\n\"\n",
        "\n",
        "    prompt = f\"{system_prompt}\\n\\n{conversation}\"\n",
        "    result = llm_local.invoke(prompt)\n",
        "    user_memory_store[user_id] = result\n",
        "    print(f\"[✅ 記憶更新] {user_id} => {result}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "# 定義圖流程\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "builder.add_node(\"write_memory\", write_memory)\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", \"write_memory\")\n",
        "builder.add_edge(\"write_memory\", END)\n",
        "# 建立圖：含短期記憶 + 長期記憶儲存\n",
        "memory = MemorySaver()\n",
        "store = InMemoryStore()\n",
        "graph = builder.compile(checkpointer=memory, store=store)\n",
        "\n"
      ],
      "metadata": {
        "id": "5czQ-VSKBICQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e38e200-c350-4563-ef19-9cb90a066ff0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View\n",
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  pass"
      ],
      "metadata": {
        "id": "KPPiEQpvHKl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "40e3eb96-3ae4-4364-a324-63a83f6ec2ab"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 測試使用者 A - Ken\n",
        "config_ken = {\n",
        "    \"configurable\": {\n",
        "        \"mode\": \"local\",\n",
        "        \"thread_id\": \"t_ken\",\n",
        "        \"user_id\": \"u01\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# 測試使用者 B - Lily\n",
        "config_lily = {\n",
        "    \"configurable\": {\n",
        "        \"mode\": \"local\",\n",
        "        \"thread_id\": \"t_lily\",\n",
        "        \"user_id\": \"u02\"\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "S0qqSCme7tvn"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"我叫Ken，喜歡動畫和日文\"}]},\n",
        "    config_ken\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"Ken 🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL6EnTjL7vTX",
        "outputId": "7c62b68a-110d-4f92-f880-d1c5c7962236"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ken 🤖  你好，Ken！很高兴能帮助你。关于你喜欢的动画和日文，我会尽我所能为你提供帮助。请随时告诉我你的问题，我会尽力回答你的问题。\n",
            "[✅ 記憶更新] u01 => \n",
            "使用者: 我希望能了解一下日本的文化和歷史\n",
            "助理: 好的，Ken，我会为你整理一些关于日本文化和历史的资料。请稍 equa，我会尽快提供给你。\n",
            "\n",
            "使用者: 谢谢，我期待你的回答\n",
            "助理: 非常欢迎，Ken。日本的文化和历史非常丰富。日本是一个岛国，位于东亚，由四个主岛和许多小岛组成。日本的历史可以追朔至约5000年前，当时的原住民是一个称为“Jomon”的文化。在1853年，日本被美国海軍逼开门，开始与世界进行交流。1868年，日本建立了“明治”时代，进行了一系列的政治、经济和社会改革。日本的文化受到中国、韩国和西方国家的影响，结合了独特的日本元素。日本的传统文化包括茶道、弥足、独角坂、和歌、画卷、纸画等。日本的历史和文化非常丰富，我会尽量为你提供更多信息。请随时告诉我你的问题。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"我是Lily，我愛旅行和美食\"}]},\n",
        "    config_lily\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"Lily 🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efX3SxxR7vaO",
        "outputId": "bc4db9cd-b0c8-40cc-9e8a-85bc7cb5a857"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lily 🤖 嗨，Lily！我很高興能認識你，一起分享旅行和美食的樂趣！旅行和美食是生活中的兩大享受，它們能豐富我們的生活體驗，讓我們認識不同的文化和文化。\n",
            "\n",
            "旅行方面，我最喜歡去不同的國家和城市，體驗當地的文化、歷史和自然風光。我特別喜歡歐洲的歷史古城，如義大利的羅馬、法國的巴黎和西班牙的馬德里，它們的建築、藝術和美食都非常吸引人。亞洲的日本和韓國也是我的旅行目的地，這裡的文化和自然美景也非常迷人。\n",
            "\n",
            "美食方面，我非常享受品嚐各地的特色料理。義大利的披薩和義大利麵、法國的法式甜點、日本的壽司和拉麵、韓國的泡菜和烤肉，每一種都讓我大呼過癮。當然，我也很喜歡台灣的在地美食，如小籠包、牛肉麵、珍珠奶茶等。\n",
            "\n",
            "如果你有任何旅行或美食方面的問題，都可以隨時和我分享，我非常樂意為你提供建議和推薦！\n",
            "[✅ 記憶更新] u02 => \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for event in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"你有推薦的動畫嗎？\"}]},\n",
        "    config_ken\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"Ken 🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "id": "fusV07Gz7vg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for event in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"你知道哪裡有好吃的嗎？\"}]},\n",
        "    config_lily\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"Lily 🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G3BKb-171TQ",
        "outputId": "ee9471e6-f2a3-4dbb-edd8-b75ceadca989"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'messages': [{'role': 'user', 'content': '你知道哪裡有好吃的嗎？'}]},)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_memory_store\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp7QFoJ171Y-",
        "outputId": "3fdca687-698e-49f0-b538-2eb4edc49236"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'u01': '\\n使用者: 我希望能了解一下日本的文化和歷史\\n助理: 好的，Ken，我会为你整理一些关于日本文化和历史的资料。请稍 equa，我会尽快提供给你。\\n\\n使用者: 谢谢，我期待你的回答\\n助理: 非常欢迎，Ken。日本的文化和历史非常丰富。日本是一个岛国，位于东亚，由四个主岛和许多小岛组成。日本的历史可以追朔至约5000年前，当时的原住民是一个称为“Jomon”的文化。在1853年，日本被美国海軍逼开门，开始与世界进行交流。1868年，日本建立了“明治”时代，进行了一系列的政治、经济和社会改革。日本的文化受到中国、韩国和西方国家的影响，结合了独特的日本元素。日本的传统文化包括茶道、弥足、独角坂、和歌、画卷、纸画等。日本的历史和文化非常丰富，我会尽量为你提供更多信息。请随时告诉我你的问题。'}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQ6mnD_W71gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str, config: dict):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
        "        if \"chatbot\" in event:\n",
        "          for value in event.values():\n",
        "              print(\"Assistant:\", value[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "zjdk4Y1tvXyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用者A的第一次對話\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation_1\", \"user_id\": \"user_a\"}}"
      ],
      "metadata": {
        "id": "GMyA_OCNBIEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 開始對話 (可以輸入quit, exit, q，三選一停止對話)\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input, config)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break"
      ],
      "metadata": {
        "id": "GTx7BfHTvVVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用者A的第二次對話\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation_2\", \"user_id\": \"user_a\"}}"
      ],
      "metadata": {
        "id": "hnwxAcAqvgzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 開始對話 (可以輸入quit, exit, q，三選一停止對話)\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input, config)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break"
      ],
      "metadata": {
        "id": "qOyjZJ_HvmIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) 進階版\n",
        "\n",
        "👨‍🎓 [進階版]\n",
        "- chatbot node: 可以決定使用者的問題是否需要從長期記憶中取得資訊，以及需要取得什麼資訊\n",
        "- write_memory node: 可以整理成特定格式 (例如：使用with_structured_output，相關概念可以延伸到R3 tool calling內容)。例如：\n",
        "```\n",
        "user_profile = {\n",
        "  \"first_name\": \"XXXX\",\n",
        "  \"last_name\": \"OOO\",\n",
        "  \"preferred_lang\": [\"en\", \"zh-tw\"]\n",
        "}\n",
        "```\n",
        "- 也可以自行將graph結構調整自己喜歡的(增刪不同node, conditional router, ...)"
      ],
      "metadata": {
        "id": "2qIEWoYKwExU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 💻code here, enjoy the ride 😎\n"
      ],
      "metadata": {
        "id": "5MLcnXZAwHeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph langchain pydantic\n"
      ],
      "metadata": {
        "id": "cr37MdZ5HjUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, List\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain.output_parsers.pydantic import PydanticOutputParser\n",
        "from langchain.output_parsers.string import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "# 🧠 模擬本地模型的回應邏輯\n",
        "class DummyLLM:\n",
        "    def invoke(self, prompt, config=None):\n",
        "        if \"輸出 JSON 格式\" in prompt:\n",
        "            return '''{\n",
        "                \"first_name\": \"Ken\",\n",
        "                \"last_name\": \"Wang\",\n",
        "                \"preferred_lang\": [\"zh-tw\", \"ja\"],\n",
        "                \"interests\": [\"動畫\", \"日文\"]\n",
        "            }'''\n",
        "        return \"這是個人化回應：我記得你喜歡動畫和日文喔！\"\n",
        "\n",
        "# 🧩 封裝成 Runnable 讓它可以進入管線\n",
        "class LocalLLMRunnable(Runnable):\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "    def invoke(self, input, config=None):\n",
        "        return self.llm.invoke(input)\n",
        "\n",
        "llm_local = LocalLLMRunnable(DummyLLM())\n",
        "\n",
        "# 🎯 定義 Graph 所需狀態結構\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# 🗂️ 定義 User Profile 格式\n",
        "class UserProfile(BaseModel):\n",
        "    first_name: str\n",
        "    last_name: str\n",
        "    preferred_lang: List[str]\n",
        "    interests: List[str]\n",
        "\n",
        "user_memory_store = {}\n",
        "\n",
        "# 📋 記憶結構化解析鏈\n",
        "output_parser = PydanticOutputParser(pydantic_object=UserProfile)\n",
        "memory_prompt = PromptTemplate.from_template(\n",
        "    \"根據以下對話紀錄，整理使用者的資訊並輸出 JSON 格式：\\n\\n{messages}\\n\\n{format_instructions}\",\n",
        "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
        ")\n",
        "structured_chain = memory_prompt | llm_local | StrOutputParser() | output_parser\n"
      ],
      "metadata": {
        "id": "jyJZA50xwZBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🤖 chatbot node：有條件引用長期記憶\n",
        "def chatbot(state: dict, config: dict):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    mode = config[\"configurable\"][\"mode\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    last_user_msg = \"\"\n",
        "    for msg in reversed(messages):\n",
        "        if msg.type == \"human\":\n",
        "            last_user_msg = msg.content\n",
        "            break\n",
        "\n",
        "    use_memory = any(k in last_user_msg.lower() for k in [\"記得\", \"推薦\", \"我\", \"你知道我\"])\n",
        "\n",
        "    user_profile = user_memory_store.get(user_id, None) if use_memory else None\n",
        "    system_prompt = \"你是一個只能用繁體中文回答的助理\"\n",
        "    if user_profile:\n",
        "        system_prompt += f\"，請根據下列使用者資訊給出個人化回答：{user_profile}\"\n",
        "\n",
        "    conversation = \"\"\n",
        "    for msg in messages:\n",
        "        if msg.type == \"human\":\n",
        "            conversation += f\"使用者: {msg.content}\\n\"\n",
        "        elif msg.type == \"ai\":\n",
        "            conversation += f\"助理: {msg.content}\\n\"\n",
        "\n",
        "    prompt = f\"{system_prompt}\\n\\n{conversation}\\n助理:\"\n",
        "    response = llm_local.invoke(prompt)\n",
        "    return {\"messages\": [AIMessage(content=response)]}\n",
        "\n",
        "# 🧠 write_memory node：將使用者資訊結構化\n",
        "def write_memory(state: dict, config: dict):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    conversation = \"\"\n",
        "    for msg in messages:\n",
        "        if msg.type == \"human\":\n",
        "            conversation += f\"使用者: {msg.content}\\n\"\n",
        "        elif msg.type == \"ai\":\n",
        "            conversation += f\"助理: {msg.content}\\n\"\n",
        "\n",
        "    try:\n",
        "        profile = structured_chain.invoke({\"messages\": conversation})\n",
        "        user_memory_store[user_id] = profile.dict()\n",
        "        print(f\"[✅ 記憶已結構化] {user_id} => {profile.dict()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[⚠️ 結構化失敗] {e}\")\n",
        "        user_memory_store[user_id] = {}\n",
        "\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "icShHI4sJouA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "builder.add_node(\"write_memory\", write_memory)\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", \"write_memory\")\n",
        "builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "# ✅ 編譯流程圖\n",
        "memory = MemorySaver()\n",
        "store = InMemoryStore()\n",
        "graph = builder.compile(checkpointer=memory, store=store)\n",
        "\n",
        "# ✅ 建立測試者 config\n",
        "config_ken = {\n",
        "    \"configurable\": {\n",
        "        \"user_id\": \"u01\",\n",
        "        \"mode\": \"local\",\n",
        "        \"thread_id\": \"ken-thread-001\"\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "HxJxUUy0Jrm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔁 第一次對話：建立記憶\n",
        "for event in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"我叫Ken Wang，喜歡動畫和日文，常用語言是中文跟日文\")]},\n",
        "    config_ken\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n",
        "    elif \"write_memory\" in event:\n",
        "        print(\"🧠 記憶建立完成\")\n",
        "\n",
        "# 🔁 第二次對話：測試是否使用記憶回應\n",
        "for event in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"你可以推薦我一些動畫嗎？\")]},\n",
        "    config_ken\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "id": "xlIZsLOMJvlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 測試 config 設定\n",
        "config_ken = {\n",
        "    \"configurable\": {\n",
        "        \"user_id\": \"u01\",\n",
        "        \"mode\": \"local\",\n",
        "        \"thread_id\": \"ken-thread-001\"  # 任意命名，只要唯一即可\n",
        "    }\n",
        "}\n",
        "# 第一次對話：建立記憶\n",
        "for event in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"我叫Ken Wang，喜歡動畫和日文，常用語言是中文跟日文\")]},\n",
        "    config_ken\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n",
        "    elif \"write_memory\" in event:\n",
        "        print(\"🧠 記憶已建立\")\n",
        "\n",
        "# 第二次對話：記憶回應測試\n",
        "for event in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"你可以推薦我一些動畫嗎？\")]},\n",
        "    config_ken\n",
        "):\n",
        "    if \"chatbot\" in event:\n",
        "        print(\"🤖\", event[\"chatbot\"][\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUeRfmon-aeD",
        "outputId": "1bb69b9c-42b0-4942-c266-b00e6cd68ef7"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 這是個人化回應：我記得你喜歡動畫和日文喔！\n",
            "[⚠️ 結構化失敗] Invalid json output: 這是個人化回應：我記得你喜歡動畫和日文喔！\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "🧠 記憶已建立\n",
            "🤖 這是個人化回應：我記得你喜歡動畫和日文喔！\n",
            "[⚠️ 結構化失敗] Invalid json output: 這是個人化回應：我記得你喜歡動畫和日文喔！\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
          ]
        }
      ]
    }
  ]
}